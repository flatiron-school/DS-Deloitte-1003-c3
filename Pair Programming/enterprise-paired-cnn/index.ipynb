{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Networks & COVID-19 Omicron and Delta Variant Lung CT Scans"
      ],
      "metadata": {
        "id": "YTfR1wGt3FZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data & Kaggle"
      ],
      "metadata": {
        "id": "b__m9yd53NOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the dataset"
      ],
      "metadata": {
        "id": "MV_LkpSR3SJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the COVID-19 pandemic was waning in most parts of the world, a new wave of COVID-19 Omicron and Delta variants in central Asia and the Middle East caused a devastating crisis and collapse of health care systems. As the diagnostic methods for this COVID-19 variant became more complex, healthcare centers faced a dramatic increase in patients. Thus, the need for less expensive and faster diagnostic methods led researchers and specialists to work on improving diagnostic testing.\n",
        "\n",
        "This is a large public COVID-19 (Omicron and Delta Variant) lung CT scan [dataset](https://www.kaggle.com/datasets/mohammadamireshraghi/covid19-omicron-and-delta-variant-ct-scan-dataset). it contains 14,482 CT scans which include 12,231 positive cases (COVID-19 infection) and 2251 negative ones (normal and non-COVID-19). Data is available as 512×512px JPG images and have been collected from patients in radiology centers of teaching hospitals of Tehran, Iran. "
      ],
      "metadata": {
        "id": "0eVMC1wN3kjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Colab"
      ],
      "metadata": {
        "id": "B4NOLk8s0Wfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google [Colab](https://colab.research.google.com/) is Google notebook with features of visual studio. We will be using Google Colab for this lab for a few reasons.\n",
        "\n",
        "*   If you are not familar with , you should become so.\n",
        "*   It is easier to bring in the data from [Kaggle](https://www.kaggle.com/) (see below) via Colab, particularly when students have a myriad of types of computers and plethora of set-ups on those computers.\n",
        "*   It can connect directly to GitHub.\n",
        "\n"
      ],
      "metadata": {
        "id": "JovFvxwU0Zpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kaggle"
      ],
      "metadata": {
        "id": "yR79Gfhj3slj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaZwFrQ2rtyI"
      },
      "source": [
        "While the data set could be downloaded from Kaggle via your browser and then you could upload all of the data into your notebook, that is not efficient since the data is over 1.5 GB. Thus, we want to connect to Kaggle so that we can download the data diectly. Here is the process.\n",
        "\n",
        "1.   Go to kaggle.com and log-in or create an account.\n",
        "2.   On the upper tab, click on 'Account'.\n",
        "3.   Once you do that, you'll see *API* and below that, \"Create New API Token.\"\n",
        "4.   After clicking the \"Create New API Token,\" a file named \"kaggle.json\" will be downloaded.\n",
        "5.   Upload this file into your Colab notebook, just as you would with a data set.\n",
        "\n",
        "N.B. You can reuse the same .json file, you don't need to create a new API token each time you want to connect to Kaggle.\n",
        "\n",
        "*Before proceeding to the code immediately below, make sure to place kaggle.json in your Colab notebook Files.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIrgmE2FoqYT",
        "outputId": "03dd4aa4-6b55-4fe3-db25-bf5fb5e13c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# We are using Unix commands (each begins with '!') to connect to Kaggle and get the data.\n",
        "\n",
        "# Set-up the Kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copy the json file to this new directory.\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Allow access to the directory\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# List the names of the files in the directory\n",
        "!ls ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8OPqu-wraXY",
        "outputId": "35c2cff7-7501-455c-d274-2cd436b3026d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 74 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 31.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 55.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lxml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for lxml\u001b[0m\n",
            "\u001b[?25h  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "    Running setup.py install for lxml ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-hnlxnhyu/lxml_c7afa52f268949efad0c45038e335816/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-hnlxnhyu/lxml_c7afa52f268949efad0c45038e335816/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-q7i_yxkp/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/lxml Check the logs for full command output.\u001b[0m\n",
            "Downloading covid19-omicron-and-delta-variant-ct-scan-dataset.zip to /content\n",
            "100% 1.55G/1.55G [00:09<00:00, 187MB/s]\n",
            "100% 1.55G/1.55G [00:09<00:00, 167MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Install Kaggle packages\n",
        "\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli\n",
        "\n",
        "# Download the data set\n",
        "!kaggle datasets download -d mohammadamireshraghi/covid19-omicron-and-delta-variant-ct-scan-dataset\n",
        "\n",
        "# Remove the working directory\n",
        "!rm -rf /kaggle/working/*\n",
        "\n",
        "# If you get any errors, its likely due to conflicts in the Python versions and the Unix versions,\n",
        "# but they should not be an issue. They are more warnings, then errors.\n",
        "# As long as it downloads the data, you're fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgxxaMj8sEpi"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "\n",
        "!unzip covid19-omicron-and-delta-variant-ct-scan-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CNLNiXeuU3H"
      },
      "source": [
        "### Import the germane libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdRkGTtUuSPe"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pathlib\n",
        "import PIL\n",
        "\n",
        "# import your machine learning libraries here \n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx25o6OXuib5"
      },
      "source": [
        "## Preprocessing and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set-up the folders and count the data"
      ],
      "metadata": {
        "id": "ETzXRM4H6mVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlBFyoYuukUY"
      },
      "outputs": [],
      "source": [
        "# Create folders for the two types of data.\n",
        "\n",
        "data_dir_covid = pathlib.Path('../content/COVID19_Omicron_and_Delta_CT_Scans_dataset/COVID')\n",
        "data_dir_non_covid = pathlib.Path('../content/COVID19_Omicron_and_Delta_CT_Scans_dataset/Non_COVID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhTZM5mwuukd"
      },
      "outputs": [],
      "source": [
        "# Count the number of .jpg files in each folder.\n",
        "img_count_covid = len(list(data_dir_covid.glob('*.jpg'))) \n",
        "img_count_non_covid = len(list(data_dir_non_covid.glob('*.jpg'))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o_fQTzlu7Q9"
      },
      "outputs": [],
      "source": [
        "# Print the image counts\n",
        "print(\"Image count in Covid set: \",img_count_covid)\n",
        "print(\"Image count in Non Covid set: \",img_count_non_covid)\n",
        "print(\"Total Image count: \",(img_count_covid+img_count_non_covid))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing some images"
      ],
      "metadata": {
        "id": "6X8ITA6Y62Q-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RckQw7de47y5"
      },
      "outputs": [],
      "source": [
        "# Let's go back to the two different types of data.\n",
        "# And let's look at a couple of each type.\n",
        "\n",
        "covid = list(data_dir_covid.glob('*'))\n",
        "non_covid = list(data_dir_non_covid.glob('*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1Gda2iy5DHp"
      },
      "outputs": [],
      "source": [
        "# Images\n",
        "# Images\n",
        "img1 = PIL.Image.open(str(covid[0]))\n",
        "print(\"Image size: \" ,img1.size)\n",
        "img1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUwa31I05ItM"
      },
      "outputs": [],
      "source": [
        "img2 = PIL.Image.open(str(non_covid[0]))\n",
        "print(\"Image size: \" ,img1.size)\n",
        "img2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to look at a few more images, and try to determine if you can tell any difference between non-COVID and COVID lung scans."
      ],
      "metadata": {
        "id": "cwRO8nPf7IEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test/Validation"
      ],
      "metadata": {
        "id": "c59KVVIr7RvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll now split the data into train/test/validaiton sets using `splitfolders`."
      ],
      "metadata": {
        "id": "lwmej9aK7e7D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q_P0Ica3hVJ"
      },
      "outputs": [],
      "source": [
        "# We'll use split-folders to combine the two types of data (Covid/Non-Covid)\n",
        "# and to further split into train/test/validaiton sets.\n",
        "\n",
        "# Install split-folders\n",
        "!pip install split-folders\n",
        "\n",
        "# Using Split-folders to split source folder into the\n",
        "# train (70%), test (20%), and validation (10%).\n",
        "\n",
        "# Set the seed to 1882, so that we can replicate the results.\n",
        "\n",
        "import splitfolders\n",
        "splitfolders.ratio(\"../content/COVID19_Omicron_and_Delta_CT_Scans_dataset\", output=\"../working/dataset\",\n",
        "    seed=1882, ratio=(.7, .2, .1), group_prefix=None, move=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define a path for of the three sets, and like before count the images and print to verify all has gone correctly."
      ],
      "metadata": {
        "id": "3KzyEC237xew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPDGxC1I3t1o"
      },
      "outputs": [],
      "source": [
        "# Define the path for train, validation and test set\n",
        "\n",
        "data_dir_train = pathlib.Path('../working/dataset/train')\n",
        "data_dir_test = pathlib.Path('../working/dataset/test')\n",
        "data_dir_val = pathlib.Path('../working/dataset/val')\n",
        "\n",
        "# Check the total image counts (all images are of type .png).\n",
        "\n",
        "img_count_train = len(list(data_dir_train.glob('*/*.jpg'))) \n",
        "img_count_test = len(list(data_dir_test.glob('*/*.jpg'))) \n",
        "img_count_val = len(list(data_dir_val.glob('*/*.jpg'))) \n",
        "\n",
        "img_count_tot = img_count_train + img_count_test + img_count_val\n",
        "\n",
        "print(\"Image count in Train set: \",img_count_train)\n",
        "print(\"Image count in Val set: \",img_count_val)\n",
        "print(\"Image count in Test set: \",img_count_test)\n",
        "print(\"Total image count\",img_count_tot)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping the data"
      ],
      "metadata": {
        "id": "PKFIhAAE7_Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data images are 512 by 512, we need to rescale the data."
      ],
      "metadata": {
        "id": "l6bazkhA8lcx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGxcMjgvKe_A"
      },
      "outputs": [],
      "source": [
        "# Reshape the data\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./511).flow_from_directory(\n",
        "    data_dir_train,\n",
        "    target_size = (128,128),\n",
        "    batch_size = 10136)\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./511).flow_from_directory(\n",
        "    data_dir_val,\n",
        "    target_size = (128,128),\n",
        "    batch_size = 2896)\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale=1./511).flow_from_directory(\n",
        "    data_dir_test,\n",
        "    target_size = (128,128),\n",
        "    batch_size = 1450)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to have images and their labels."
      ],
      "metadata": {
        "id": "5GVxqJ-Y8bND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJicT1pgEu6C"
      },
      "outputs": [],
      "source": [
        "# Create the data sets\n",
        "train_images, train_labels = next(train_gen)\n",
        "test_images, test_labels = next(test_gen)\n",
        "val_images, val_labels = next(val_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "Wp_yfUdA6MGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Generator"
      ],
      "metadata": {
        "id": "7f2t95H09sfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we get to convolution neural networks, we need to set-up the machinery for the CNN.\n",
        "\n",
        "A data generator allows Python to be more effiecent in reading the data. This is particular important for visual data. While Keras has built in data generator, from `tensorflow.keras.preprocessing.image.ImageDataGenerator`, it has limited flexibility. So, we'll create our own."
      ],
      "metadata": {
        "id": "YcihkMgc91I8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gQkHAmLUtCr"
      },
      "outputs": [],
      "source": [
        " # Custom data generator\n",
        "\n",
        "def data_generator(data_source,img_height, img_width, btc_size):    \n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        data_source,\n",
        "        validation_split=None, # We already split the data\n",
        "        subset=None,\n",
        "        seed=123,\n",
        "        color_mode='grayscale',\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=btc_size,\n",
        "        crop_to_aspect_ratio=True,\n",
        "        shuffle=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the inital values for the batch size and the number of epochs.\n",
        "\n",
        "Be careful/patient with the bactch size and the number of epochs... this may take quite some time to run depending on your choices."
      ],
      "metadata": {
        "id": "eJhdAs3L3ZRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We now need to set the (initial) values of the hyperparameters.\n",
        "batch_size = 'none'\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "num_epochs = 'none'"
      ],
      "metadata": {
        "id": "fNdw7G40GFYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `data_generator` on the three subsets of the data."
      ],
      "metadata": {
        "id": "UNOd2Pl--fXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying data_generator\n",
        "\n",
        "train_ds = data_generator(data_dir_train,img_height, img_width, batch_size)\n",
        "val_ds = data_generator(data_dir_val,img_height, img_width, batch_size)\n",
        "test_ds = data_generator(data_dir_test,img_height, img_width, batch_size)"
      ],
      "metadata": {
        "id": "qeNsP_k0GQBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll need the class names\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "pnOcmV5ZGR2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some further model preperation"
      ],
      "metadata": {
        "id": "i7Qj-C20_WSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few more items to take care of before we train our model.\n",
        "\n",
        "We'll start with our number of classes."
      ],
      "metadata": {
        "id": "40nqLQxU_c_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "id": "x1eYY3UjGU6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make sure our layers are scaled as well."
      ],
      "metadata": {
        "id": "7a72BPQC_EF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescaling \n",
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "H3lRM_ZNGbwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make life easier, let's define a function that will print the parameters for us."
      ],
      "metadata": {
        "id": "cPLQ9CDu_MAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for printing parameters\n",
        "def print_param():\n",
        "    print(\"*** Params used in Model Training ****\")\n",
        "    print(\"Batch Size: \", batch_size)\n",
        "    print(\"Epoch Size: \", num_epochs)\n",
        "    print(\"Image size: {} {}\".format(img_height, img_width))\n",
        "    print(\"***********************\")"
      ],
      "metadata": {
        "id": "T5DGVlRQGd8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining our training model"
      ],
      "metadata": {
        "id": "8WqJow-u_r0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_init: str, which is a string to be prefixed in model checkpoint name.\n",
        "\n",
        "def train_model(model_init, model):\n",
        "    \n",
        "    #Create training and validation sets\n",
        "    train_ds = data_generator(data_dir_train,img_height, img_width, batch_size)\n",
        "    val_ds = data_generator(data_dir_val,img_height, img_width, batch_size)\n",
        "    test_ds = data_generator(data_dir_test,img_height, img_width, batch_size)\n",
        "\n",
        "    # File name for model checkpoint\n",
        "    curr_dt_time = datetime.datetime.now()\n",
        "    model_name = model_init + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "    if not os.path.exists(model_name):\n",
        "        os.mkdir(model_name)\n",
        "\n",
        "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{accuracy:.5f}-{val_loss:.5f}-{val_accuracy:.5f}.h5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    \n",
        "    # Stop Training, if no improvement observed.\n",
        "    Earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=7,verbose=1)\n",
        "    \n",
        "    # Reduce learning rate when performance metric stopped improving.\n",
        "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5,\n",
        "                           cooldown=4, verbose=1,mode='auto',epsilon=0.0001)\n",
        "    \n",
        "    callbacks_list = [checkpoint, LR, Earlystop]        \n",
        "    \n",
        "    # Print parameters used for model training using the functiond defined above.\n",
        "    print_param()\n",
        "    \n",
        "    start = time.time()\n",
        "    history = model.fit(train_ds, epochs=num_epochs, verbose=1, \n",
        "                    callbacks=callbacks_list, validation_data=val_ds, \n",
        "                    class_weight=None, workers=1, initial_epoch=0)\n",
        "    end = time.time()\n",
        "    print(\"Total training time: \", \"{:.2f}\".format((end-start)), \" secs\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "JXa8CegFGd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a another definition so that we can print the metrics with ease."
      ],
      "metadata": {
        "id": "Ob3hqTxR_631"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics function\n",
        "\n",
        "def plot_metrics(history):       \n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(num_epochs)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vz_A4_dJGnks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and compile the model"
      ],
      "metadata": {
        "id": "BKp6NGBcAFCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are finally ready to go. Time for you to define your model and then compile it.\n",
        "\n",
        "Since this is a large image data set, the model will possibly take some time to run. Make sure to use regularization techniques to guard against overfitting (variance) and to reduce the runtime.\n",
        "\n",
        "As a reminder, in `train_model` above, we have already included both `EarlyStopping` and `ReduceLROnPlateau`."
      ],
      "metadata": {
        "id": "eRTEYhx0AN1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "\n",
        "model1 = Sequential([\n",
        " \n",
        " # Build your CNN here\n",
        "\n",
        "    ])"
      ],
      "metadata": {
        "id": "LgezzjVRGrO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give the model summary"
      ],
      "metadata": {
        "id": "43QlmsMmAmio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the model\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "Ows9OaSsGvwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "Ho7vkccmAqSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "               metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "RcbJTSgKGtME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the inital hyperparamters to experiment.\n"
      ],
      "metadata": {
        "id": "idhLJdD9BWF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting hyperparameters to experiment\n",
        "\n",
        "batch_size= 'none'\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "num_epochs = 'none'"
      ],
      "metadata": {
        "id": "qEG0fZA9BbG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model."
      ],
      "metadata": {
        "id": "pSXIkvRkCFIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_model1 = train_model(\"model1\",model1)"
      ],
      "metadata": {
        "id": "B5GwbzGHB-lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the metrics."
      ],
      "metadata": {
        "id": "0v84RP0mCIBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics\n",
        "num_epochs = len(history_model1.history['loss'])\n",
        "plot_metrics(history_model1)"
      ],
      "metadata": {
        "id": "kbq-CPatCCsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model accuracy on the test set"
      ],
      "metadata": {
        "id": "ctzMLCpk5qZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So how did you do?"
      ],
      "metadata": {
        "id": "N2zXRUKw32iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model1.predict(test_ds)\n",
        "bin_predict = np.argmax(pred,axis=1)"
      ],
      "metadata": {
        "id": "iHXCJbjD5pRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model1.evaluate(test_ds, batch_size=batch_size, verbose=2)"
      ],
      "metadata": {
        "id": "zrbFPPBebgN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue to modify your model until you are happy with it, i.e. when you find the optimal model."
      ],
      "metadata": {
        "id": "3qXEhRYXzrhL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}